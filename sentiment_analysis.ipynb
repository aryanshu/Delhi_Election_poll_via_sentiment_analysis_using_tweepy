{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Delhi_Election _poll_2020_via_sentiment_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8JbiPsiWm686Nqdo7vy60",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanshu/Delhi_Election_poll_via_sentiment_analysis_using_tweepy/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJWuI61O4Ojv",
        "colab_type": "code",
        "outputId": "278d5cd8-a671-4e4b-eca1-f0180500462f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3opPJuE4Q4N",
        "colab_type": "code",
        "outputId": "4921e2b2-62bc-42a5-924a-20123d7428f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/gdrive/My Drive/Colab Notebooks'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnobRcjIuS7",
        "colab_type": "code",
        "outputId": "5674bc23-2a63-404b-d8ce-87f0f1d2cc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install tweepy\n",
        "!pip install textblob\n",
        "!pip install jsonpickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79vGctrw4z3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import tweepy \n",
        "from tweepy import OAuthHandler \n",
        "from textblob import TextBlob \n",
        "from tweepy import API \n",
        "from tweepy import Cursor\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import Stream\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "\n",
        "API_KEY='MuTZu584Tok038SCEojrjrKRe'\n",
        "API_SECRET='fsBbryvLU1pKRxXYGtKbuW5v7qZEMBVYXmzvT8aEqnbTKo7mgj'\n",
        "auth = tweepy.AppAuthHandler(API_KEY, API_SECRET)\n",
        "\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True,\n",
        "\t\t\t\t   wait_on_rate_limit_notify=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHVlpqV3bDQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetAnalyzer():\n",
        "    \"\"\"\n",
        "    Functionality for analyzing and categorizing content from tweets.\n",
        "    \"\"\"\n",
        "\n",
        "    def clean_tweet(self, tweet):\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "    def analyze_sentiment(self, tweet):\n",
        "        analysis = TextBlob(self.clean_tweet(tweet))\n",
        "        \n",
        "        if analysis.sentiment.polarity > 0:\n",
        "            return 1\n",
        "        elif analysis.sentiment.polarity == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def tweets_to_data_frame(self, tweets):\n",
        "        df = pd.DataFrame(data=[tweet.text[:150] for tweet in tweets], columns=['tweets'])\n",
        "\n",
        "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
        "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
        " \n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLILbNi9opjP",
        "colab_type": "code",
        "outputId": "98bb5935-c6fd-494c-9dbf-e91f47e03902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "import jsonpickle\n",
        "import os\n",
        "\n",
        "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
        "def tweet_collect(query,maxTweets=1000,fName='tweets.txt',until=None):\n",
        "  sinceId = None\n",
        "  tweets=[]\n",
        "  max_id =-1000000\n",
        "\n",
        "  tweetCount = 0\n",
        "  searchQuery = query  \n",
        "  tweetsPerQry = 100 \n",
        "  with open(fName, 'w') as f:\n",
        "      while tweetCount < maxTweets:\n",
        "          try:\n",
        "              if (max_id <= 0):\n",
        "                  if (not sinceId):\n",
        "                      new_tweets = api.search(q=searchQuery, count=tweetsPerQry,lang=\"en\",wait_on_rate_limit=True,\n",
        "                                geocode='28.644800,77.216721,20km',until=until)\n",
        "                  else:\n",
        "                      new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
        "                                              since_id=sinceId,lang=\"en\",wait_on_rate_limit=True,\n",
        "                                geocode='28.644800,77.216721,20km',until=until)\n",
        "              else:\n",
        "                  if (not sinceId):\n",
        "                      new_tweets = api.search(q=searchQuery, count=tweetsPerQry,lang=\"en\",wait_on_rate_limit=True,\n",
        "                                geocode='28.644800,77.216721,20km',until=until,\n",
        "                                              max_id=str(max_id - 1))\n",
        "                  else:\n",
        "                      new_tweets = api.search(q=searchQuery, count=tweetsPerQry,lang=\"en\",wait_on_rate_limit=True,\n",
        "                                geocode='28.644800,77.216721,20km',until=until,\n",
        "                                              max_id=str(max_id - 1),\n",
        "                                              since_id=sinceId)\n",
        "              if not new_tweets:\n",
        "                  print(\"No more tweets found\")\n",
        "                  break\n",
        "              for tweet in new_tweets:\n",
        "                  f.write(jsonpickle.encode(tweet._json, unpicklable=False) +\n",
        "                          '\\n')\n",
        "                  tweets.append(tweet)\n",
        "              tweetCount += len(new_tweets)\n",
        "              print(\"Downloaded {0} tweets\".format(tweetCount))\n",
        "              max_id = new_tweets[-1].id\n",
        "          except tweepy.TweepError as e:\n",
        "              # Just exit if any error\n",
        "              print(\"some error : \" + str(e))\n",
        "              break\n",
        "\n",
        "  print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))\n",
        "  return tweets\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading max 15000 tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZHu0_sx0kXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets=[]\n",
        "for i in range(1,9):\n",
        "  until='2020-2-'+str(i)\n",
        "  tweet_on=tweet_collect(query='AAP',maxTweets=20000,until=until)\n",
        "  tweets=tweets+tweet_on\n",
        "\n",
        "tweets2=[]\n",
        "for i in range(1,9):\n",
        "  until='2020-2-'+str(i)\n",
        "  tweet_on2=tweet_collect(query='BJP',maxTweets=20000,until=until)\n",
        "  tweets2=tweets2+tweet_on2\n",
        "  \n",
        "tweets3=[]\n",
        "for i in range(1,9):\n",
        "  until='2020-2-'+str(i)\n",
        "  tweet_on=tweet_collect(query='CONGRESS',maxTweets=10000,until=until)\n",
        "  tweets3=tweets3+tweet_on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ezNUyy-v8L",
        "colab_type": "code",
        "outputId": "ddb0fefc-bd4f-4db6-f7b7-1adefb1709e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.to_csv('AAP_tweet.csv')\n",
        "df2.to_csv('BJP_tweet.csv')\n",
        "df3.to_csv('CONGRESS_tweet.csv')\n",
        "df.date"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2020-02-04 23:59:58\n",
              "1       2020-02-04 23:59:48\n",
              "2       2020-02-04 23:59:46\n",
              "3       2020-02-04 23:59:45\n",
              "4       2020-02-04 23:59:31\n",
              "                ...        \n",
              "38013   2020-02-07 10:35:49\n",
              "38014   2020-02-07 10:35:49\n",
              "38015   2020-02-07 10:35:47\n",
              "38016   2020-02-07 10:35:46\n",
              "38017   2020-02-07 10:35:36\n",
              "Name: date, Length: 38018, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg80vbySqk8G",
        "colab_type": "code",
        "outputId": "ddc12a86-4f27-4620-bf8f-7ecd4bbfaee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
        "print(len(df))\n",
        "df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
        "aap_positive=100*len(df['sentiment'][df['sentiment']==1])/len(df)\n",
        "aap_negative=100*len(df['sentiment'][df['sentiment']==-1])/len(df)\n",
        "t_score=aap_positive+aap_negative\n",
        "aap_score=(aap_positive)/aap_negative\n",
        "\n",
        "print('AAP positive {}%'.format(100*len(df['sentiment'][df['sentiment']==1])/len(df)))\n",
        "print('AAP negative {}%'.format(100*len(df['sentiment'][df['sentiment']==-1])/len(df)))\n",
        "print('AAP neutral {}%'.format(100*len(df['sentiment'][df['sentiment']==0])/len(df)))\n",
        "\n",
        "\n",
        "\n",
        "df2 = tweet_analyzer.tweets_to_data_frame(tweets2)\n",
        "print(len(df2))\n",
        "df2['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df2['tweets']])\n",
        "bjp_positive=100*len(df2['sentiment'][df2['sentiment']==1])/len(df2)\n",
        "bjp_negative=100*len(df2['sentiment'][df2['sentiment']==-1])/len(df2)\n",
        "t2_score=bjp_positive+bjp_negative\n",
        "bjp_score=(bjp_positive)/(bjp_negative)\n",
        "\n",
        "\n",
        "print('BJP positive {}%'.format(100*len(df2['sentiment'][df2['sentiment']==1])/len(df2)))\n",
        "print('BJP negative {}%'.format(100*len(df2['sentiment'][df2['sentiment']==-1])/len(df2)))\n",
        "print('BJP neutral {}%'.format(100*len(df2['sentiment'][df2['sentiment']==0])/len(df2)))\n",
        "\n",
        "print('AAP Adjusted Voting Percentage  {}'.format(92.5*aap_score/(aap_score+bjp_score)))\n",
        "print('BJP Adjusted Voting Percentage  {}'.format(92.5*bjp_score/(aap_score+bjp_score)))\n",
        "\n",
        "\n",
        "\n",
        "df3 = tweet_analyzer.tweets_to_data_frame(tweets3)\n",
        "print(len(df3))\n",
        "df3['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df3['tweets']])\n",
        "cong_positive=100*len(df3['sentiment'][df3['sentiment']==1])/len(df3)\n",
        "cong_negative=100*len(df3['sentiment'][df3['sentiment']==-1])/len(df3)\n",
        "t_score=cong_positive+cong_negative\n",
        "cong_score=(cong_positive)/cong_negative\n",
        "\n",
        "print('CONG positive {}%'.format(100*len(df3['sentiment'][df3['sentiment']==1])/len(df3)))\n",
        "print('CONG negative {}%'.format(100*len(df3['sentiment'][df3['sentiment']==-1])/len(df3)))\n",
        "print('CONG neutral {}%'.format(100*len(df3['sentiment'][df3['sentiment']==0])/len(df3)))\n",
        "\n",
        "print('time: {} '.format((end-start)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80347\n",
            "AAP positive 29.509502532764134%\n",
            "AAP negative 18.539584552005675%\n",
            "AAP neutral 51.95091291523019%\n",
            "57890\n",
            "BJP positive 33.70012091898428%\n",
            "BJP negative 33.10934531007082%\n",
            "BJP neutral 33.190533770944896%\n",
            "AAP Adjusted Voting Percentage  56.42073330727944\n",
            "BJP Adjusted Voting Percentage  36.07926669272056\n",
            "time: 780.7540986537933 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnh7nIetIRDg",
        "colab_type": "code",
        "outputId": "fbcc8b40-a22c-4ff7-ea60-fee93a848a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('AAP Adjusted Voting Percentage  {}'.format(100*(aap_score )/((aap_score)+bjp_score+cong_score)))\n",
        "print('BJP Adjusted Voting Percentage  {}'.format(100*(bjp_score)/(aap_score+(bjp_score)+cong_score)))\n",
        "print('cong Adjusted Voting Percentage  {}'.format(100*(cong_score)/(aap_score+bjp_score+(cong_score))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AAP Adjusted Voting Percentage  44.732836556\n",
            "BJP Adjusted Voting Percentage  29.758831419163865\n",
            "cong Adjusted Voting Percentage  25.50833202483613\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}